---
title: "Regresión Lineal R - Laboratorio 1"
author: "Juanjo Sierra"
date: "28 de noviembre de 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Regresión Lineal con R - Laboratorio 1

En primer lugar hay que leer el dataset que se va a utilizar, ubicado en la carpeta 'Datos': `california.dat`. El dataset está en formato KEEL.

```{r}
california = read.csv("../Datos/california.dat", header = FALSE, comment.char = "@")
head(california)
```

Se asignan los nombres de las variables adecuadamente.

```{r}
names(california) = c("Longitude", "Latitude", "HousingMedianAge",
"TotalRooms", "TotalBedrooms", "Population", "Households",
"MedianIncome", "MedianHouseValue")

head(california)
```

Vamos a visualizar todas las variables entre sí y respecto a la salida.

```{r}
temp = california
plotY <- function (x,y) {
plot(temp[,y]~temp[,x], xlab=paste(names(temp)[x]," X",x,sep=""),
ylab=names(temp)[y])
}
par(mfrow=c(3,3)) # Fijar ventana para gráficas
x = sapply(1:(dim(temp)[2]-1), plotY, dim(temp)[2])
par(mfrow=c(1,1)) # Cambiar el tipo de ventana a 1,1 otra vez
```

La única variable que podría resultar interesante parece ser MedianIncome. Podemos ampliar el gráfico para verla con más claridad.

```{r}
plotY(8,dim(temp)[2])
```

## Modelos lineales mútiples

Podemos probar a realizar un modelo lineal utilizando únicamente esta variable. Para ello vamos a utilizar la función `lm`.

```{r}
fit1 = lm(MedianHouseValue~MedianIncome, data=california)
summary(fit1)
```

El p-value del F-statistic nos sirve para calcular la confianza con la que afirmar que las variables mantienen una relación lineal (1 - p-value * 100 = % confianza). Ya que el p-value del F-statistic es muy pequeño la confianza es alta, con un modelo realizado con la variable MedianIncome el error de 0.4734 (nos fijamos en el Adjusted R-squared) es casi asegurado.

Podemos también probar a añadir una nueva variable al modelo, generando así un **modelo lineal múltiple**. Como ninguna variable parece especialmente prometedora, vamos a probar con TotalBedrooms, que al menos semánticamente parece relevante.

```{r}
fit2 = lm(MedianHouseValue~MedianIncome + TotalBedrooms, data=california)
summary(fit2)
```


```{r}
fit3 = lm(MedianHouseValue~MedianIncome + TotalBedrooms + TotalRooms, data=california)
summary(fit3)
```


```{r}
fit4 = lm(MedianHouseValue~MedianIncome + TotalBedrooms + TotalRooms + Households, data=california)
summary(fit4)
```

Vamos a hacerlo a la inversa: comenzamos con el modelo que tiene todas las variables y vamos eliminando las menos prometedoras.

```{r}
fit5 = lm(MedianHouseValue~., data=california)
summary(fit5)
```

Se observa un incremento considerable en el valor del R-squared del modelo, aunque también se ha incrementado su complejidad al añadir todas las variables. Se puede eliminar aquella que tiene el p-value más alto (es la menos prometedora) para ver si puede mejorar aún más.

```{r}
fit6 = lm(MedianHouseValue~.-Households, data=california)
summary(fit6)
```

El acierto del modelo disminuye muy poco (menos de un 1%) y le estamos restando complejidad, así que podemos seguir probando a eliminar variables. Como todas tienen un p-value similar ahora mismo, nos guiamos por las gráficas, y eliminamos la variable HousingMedianAge que no parece nada lineal.

```{r}
fit7 = lm(MedianHouseValue~.-Households-HousingMedianAge, data=california)
summary(fit7)
```

Ha descendido un 1% el R-squared pero para eliminar complejidad es un justo precio a pagar. Podemos seguir así eliminando variables, probando ahora con Population.

```{r}
fit8 = lm(MedianHouseValue~.-Households-HousingMedianAge-Population, data=california)
summary(fit8)
```

Eliminando esta variable el R-squared desciende por debajo de un 0.6, y aquí consideramos que es mejor mantener el modelo anterior y primar en este caso la precisión frente a la complejidad.

## Interacciones

Vamos a realizar algunas interacciones entre las variables más prometedoras que hemos encontrado realizando los modelos lineales. MedianIncome parecía ser la más interesante, realizaremos el producto entre ella y TotalBedrooms.

```{r}
fit9 = lm(MedianHouseValue~MedianIncome*TotalBedrooms, data=california)
summary(fit9)
```

Vemos que el p-value de TotalBedrooms crece un poco y que el de la variable resultante es demasiado alto. Además el R-squared obtenido no es nada reseñable. Cambiamos y probamos la variable HousingMedianAge.

```{r}
fit10 = lm(MedianHouseValue~MedianIncome*HousingMedianAge, data=california)
summary(fit10)
```

Esta variable mejora el modelo cuando se realiza el producto, por lo que es mejor que el modelo simple que se ha tomado como base. Comprobemos qué pasa si ahora añadimos la variable TotalBedrooms.

```{r}
fit11 = lm(MedianHouseValue~MedianIncome*HousingMedianAge*TotalBedrooms, data=california)
summary(fit11)
```

Ahora el resultado es mejor que al añadir solamente TotalBedrooms y MedianIncome. Y es que el producto de ambas tiene un p-value muy alto, pero la variable resultante de multiplicar las tres da un p-value bajo y el R-squared del modelo es sustancialmente mejor, por lo que aceptamos esta combinación como un mejor modelo.

## No linealidad

A continuación vamos a probar la no linealidad de alguna variable en un modelo simple. Podemos probar con MedianIncome, que parece intuir una curva cuadrática.

```{r}
fit12 = lm(MedianHouseValue~MedianIncome+I(MedianIncome^2), data=california)
summary(fit12)
```

El ajuste del modelo no muestra un gran cambio. Podemos comprobar cómo se ajusta el modelo a los valores de la variable.

```{r}
plot(california$MedianHouseValue~california$MedianIncome)
points(california$MedianIncome,fitted(fit12),col="red",pch=20)
```

Podemos probar esta no linealidad de la variable MedianIncome dentro del mejor modelo que hemos encontrado hasta ahora, el que contenía las variables MedianIncome, Latitude, Longitude, TotalRooms, TotalBedrooms y Population.

```{r}
fit13 = lm(MedianHouseValue~.+I(MedianIncome^2)-HousingMedianAge-Households,
        data=california)
summary(fit13)
```

El nuevo modelo ha mejorado al anterior, pero es más complejo y la mejora es poco sustancial (menos de un 1%), por lo que no merece la pena.